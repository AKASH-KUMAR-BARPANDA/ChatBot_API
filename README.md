# ğŸ§  FastAPI + Groq Chatbot API

This project is a **chatbot backend** built using **FastAPI** and the **Groq API** (`openai/gpt-oss-20b` model).  
It exposes a simple REST API that accepts user messages and returns chatbot responses powered by Groqâ€™s LLM.

---

## ğŸ“‚ Folder Structure

ChatBot_API/
â”‚â”€â”€ BASE_PYDANTIC/
â”‚   â””â”€â”€ BASEMODEL.py         # Pydantic request models
â”‚
â”‚â”€â”€ GROQ_SERVER/
â”‚   â””â”€â”€ GROQ_SERVER_API.py   # Groq API integration
â”‚
â”‚â”€â”€ REPOSITORY/
â”‚   â””â”€â”€ CHAT.py              # Bot response logic
â”‚
â”‚â”€â”€ ROUTERS/
â”‚   â””â”€â”€ ROUTES.py            # FastAPI routes
â”‚
â”‚â”€â”€ main.py                  # FastAPI entry point
â”‚â”€â”€ requirements.txt         # Dependencies
â”‚â”€â”€ README.md                # Project documentation

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repo
```bash
git clone https://github.com/yourusername/ChatBot_API.git
cd ChatBot_API

2ï¸âƒ£ Create & activate virtual environment
python -m venv .venv
source .venv/bin/activate   # Mac/Linux
.venv\Scripts\activate      # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Set your Groq API Key
Open GROQ_SERVER/GROQ_SERVER_API.py and add your key:
client = Groq(api_key="your_api_key_here")

ğŸ“Œ API Usage

â–¶ï¸ Run the server
uvicorn main:app --reload
The API will be available at:
http://127.0.0.1:8000


ğŸ“ Endpoint

POST /chats

Request Body
{
  "Message": "Hello Groq!"
}
Response
{
  "replay": "Hi! How can I help you today?"
}
ğŸ›  Tech Stack
	â€¢	FastAPI â†’ Web framework
	â€¢	Pydantic â†’ Request validation
	â€¢	Groq Python SDK â†’ LLM integration
	â€¢	Uvicorn â†’ ASGI server

â¸»

ğŸ“œ File Descriptions
	â€¢	BASE_PYDANTIC/BASEMODEL.py â†’ Defines request models.
	â€¢	GROQ_SERVER/GROQ_SERVER_API.py â†’ Handles Groq API requests.
	â€¢	REPOSITORY/CHAT.py â†’ Chatbot response logic.
	â€¢	ROUTERS/ROUTES.py â†’ Defines API routes.
	â€¢	main.py â†’ FastAPI entry point.

â¸»

ğŸš€ Future Improvements
	â€¢	Add streaming responses (real-time token streaming).
	â€¢	Store conversation history.
	â€¢	Deploy on Render / Railway / AWS Lambda.
	â€¢	Add frontend (React / Next.js) for chat UI.

â¸»

ğŸ“¦ Requirements

Hereâ€™s a minimal requirements.txt you can use:
fastapi
uvicorn
groq
pydantic

âœ¨ Built with FastAPI & Groq â€” simple, scalable, and blazing fast!

